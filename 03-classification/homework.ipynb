{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd, numpy as np, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv'\n",
    "!wget $data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads         NaN                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3               NaN      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1462, 9)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lead_source', 'industry', 'number_of_courses_viewed', 'annual_income',\n",
       "       'employment_status', 'location', 'interaction_count', 'lead_score',\n",
       "       'converted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.columns.str.replace(' ','_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode_industry = df['industry'].mode()[0]\n",
    "mode_industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lead_source          128\n",
       "industry             134\n",
       "annual_income        181\n",
       "employment_status    100\n",
       "location              63\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Initial Missing Values:\")\n",
    "\n",
    "df.isnull().sum()[df.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead_source', 'industry', 'employment_status', 'location']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['number_of_courses_viewed',\n",
       " 'annual_income',\n",
       " 'interaction_count',\n",
       " 'lead_score',\n",
       " 'converted']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical = list(df.dtypes[df.dtypes != 'object'].index)\n",
    "numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    df[col] = df[col].str.lower().replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                    5\n",
       "industry                       7\n",
       "number_of_courses_viewed      10\n",
       "annual_income               1267\n",
       "employment_status              4\n",
       "location                       7\n",
       "interaction_count             12\n",
       "lead_score                   101\n",
       "converted                      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical features, replace with 'NA'\n",
    "df[categorical] = df[categorical].fillna('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For numerical features, replace with 0.0\n",
    "df[numerical] = df[numerical].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values After Imputation:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nMissing Values After Imputation:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
       "0      paid_ads          NA                         1        79450.0   \n",
       "1  social_media      retail                         1        46992.0   \n",
       "2        events  healthcare                         5        78796.0   \n",
       "3      paid_ads      retail                         2        83843.0   \n",
       "4      referral   education                         3        85012.0   \n",
       "\n",
       "  employment_status       location  interaction_count  lead_score  converted  \n",
       "0        unemployed  south_america                  4        0.94          1  \n",
       "1          employed  south_america                  1        0.80          0  \n",
       "2        unemployed      australia                  3        0.69          1  \n",
       "3                NA      australia                  1        0.87          0  \n",
       "4     self_employed         europe                  3        0.62          1  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max absolute correlation: 0.02703647240481443\n",
      "Pair: ('annual_income', 'interaction_count')\n"
     ]
    }
   ],
   "source": [
    "# Select only numerical features\n",
    "numerical_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Create the correlation matrix\n",
    "correlation_matrix = numerical_df.corr()\n",
    "\n",
    "# Define the pairs to check\n",
    "pairs_to_check = [\n",
    "    ('interaction_count', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'lead_score'),\n",
    "    ('number_of_courses_viewed', 'interaction_count'),\n",
    "    ('annual_income', 'interaction_count')\n",
    "]\n",
    "\n",
    "# Find the maximum absolute correlation\n",
    "max_correlation = -1\n",
    "most_correlated_pair = None\n",
    "\n",
    "for feature1, feature2 in pairs_to_check:\n",
    "    corr_value = correlation_matrix.loc[feature1, feature2]\n",
    "    abs_corr_value = abs(corr_value)\n",
    "\n",
    "    if abs_corr_value > max_correlation:\n",
    "        max_correlation = abs_corr_value\n",
    "        most_correlated_pair = (feature1, feature2)\n",
    "\n",
    "print(f\"Max absolute correlation: {max_correlation}\")\n",
    "print(f\"Pair: {most_correlated_pair}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split happens as follows:\n",
    "\n",
    "Dataset is divided into 80% full_train + 20% test\n",
    "\n",
    "full_train is divided into 60% train + 20% validation (total 80% of dataset)\n",
    "\n",
    "train set = 75% of full_train (60% / 80%)\n",
    "\n",
    "validation set = 25% of 80% full_train (20% / 80%)\n",
    "\n",
    "(75% of full_train + 25% of full_train = 100% of full_train = 80% of dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    1    2 ... 1459 1460 1461]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(876, 293, 293)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n = len(df)\n",
    "\n",
    "idx = np.arange(n)\n",
    "print(idx)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "len(df_train), len(df_val), len(df_test)\n",
    "#print(len(df_train)+ len(df_val) +len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.converted.values\n",
    "y_val = df_val.converted.values\n",
    "y_test = df_test.converted.values\n",
    "\n",
    "del df_train['converted']\n",
    "del df_val['converted']\n",
    "del df_test['converted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted\n",
      "1    0.611634\n",
      "0    0.388366\n",
      "Name: proportion, dtype: float64\n",
      "0.611633875106929\n"
     ]
    }
   ],
   "source": [
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_full_train.isnull().sum()\n",
    "print(df_full_train.converted.value_counts(normalize=True))\n",
    "print(df_full_train.converted.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          6\n",
       "industry             8\n",
       "employment_status    5\n",
       "location             8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_train[categorical].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "def mutual_info_converted_score(series):\n",
    "    return mutual_info_score(series, df_full_train.converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source          0.024562\n",
       "employment_status    0.012690\n",
       "industry             0.008173\n",
       "location             0.001212\n",
       "dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi = df_full_train[categorical].apply(mutual_info_converted_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features after OHE: 31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "\n",
    "# Convert DataFrames to a list of dictionaries (one dict per row)\n",
    "# This is the standard input format for DictVectorizer\n",
    "train_dicts = df_train.to_dict(orient='records')\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "\n",
    "# Initialize and fit the DictVectorizer on the TRAINING set only\n",
    "dv = DictVectorizer(sparse=False) # sparse=False for easier inspection; True is default\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "# Transform the validation set using the FITTED vectorizer\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "print(f\"Number of features after OHE: {X_train.shape[1]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1. One-hot encode the training and validation sets\n",
    "# df_train_ohe = pd.get_dummies(df_train, columns=categorical)\n",
    "# df_val_ohe = pd.get_dummies(df_val, columns=categorical)\n",
    "\n",
    "# # 2. Get the full set of OHE column names from the training set\n",
    "# train_cols = df_train_ohe.columns\n",
    "\n",
    "# # 3. Align the validation set to the training set columns\n",
    "# missing_cols = set(train_cols) - set(df_val_ohe.columns)\n",
    "# for c in missing_cols:\n",
    "#     df_val_ohe[c] = 0\n",
    "\n",
    "# # 4. Filter and reorder the validation set columns\n",
    "# df_val_ohe = df_val_ohe[train_cols]\n",
    "\n",
    "# # 5. Extract values (this is your X matrix)\n",
    "# X_train = df_train_ohe.values\n",
    "# X_val = df_val_ohe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question 4 Result ---\n",
      "Validation Accuracy: 0.6997\n",
      "Rounded Accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import  accuracy_score\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy on validation set\n",
    "y_pred_val = model.predict(X_val)\n",
    "accuracy_q4 = accuracy_score(y_val, y_pred_val)\n",
    "rounded_accuracy_q4 = round(accuracy_q4, 2)\n",
    "\n",
    "print(\"\\n--- Question 4 Result ---\")\n",
    "print(f\"Validation Accuracy: {accuracy_q4:.4f}\")\n",
    "print(f\"Rounded Accuracy: {rounded_accuracy_q4}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original accuracy from Q4 (unrounded)\n",
    "original_accuracy = accuracy_q4\n",
    "\n",
    "elimination_features = ['industry', 'employment_status', 'lead_score']\n",
    "accuracy_diffs = {}\n",
    "full_feature_names = dv.get_feature_names_out()\n",
    "\n",
    "for feature_to_remove in elimination_features:\n",
    "    # --- Identify columns to drop from the OHE matrix ---\n",
    "    if feature_to_remove == 'lead_score':\n",
    "        # Numerical feature: column name is exact\n",
    "        cols_to_drop = [feature_to_remove]\n",
    "    else:\n",
    "        # Categorical feature: drop all OHE columns starting with the feature name\n",
    "        cols_to_drop = [col for col in full_feature_names if col.startswith(f'{feature_to_remove}=')]\n",
    "\n",
    "    # --- Create a new feature list without the dropped columns ---\n",
    "    features_subset_names = [col for col in full_feature_names if col not in cols_to_drop]\n",
    "\n",
    "    # --- Find the indices for the subset of features ---\n",
    "    # Convert names to indices for selection\n",
    "    indices = [np.where(full_feature_names == name)[0][0] for name in features_subset_names]\n",
    "    \n",
    "    # --- Prepare data subset ---\n",
    "    X_train_subset = X_train[:, indices]\n",
    "    X_val_subset = X_val[:, indices]\n",
    "\n",
    "    # --- Train the model (same parameters as Q4) ---\n",
    "    model_subset = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_subset.fit(X_train_subset, y_train)\n",
    "\n",
    "    # --- Calculate accuracy ---\n",
    "    y_pred_val_subset = model_subset.predict(X_val_subset)\n",
    "    accuracy_subset = accuracy_score(y_val, y_pred_val_subset)\n",
    "\n",
    "    # --- Calculate difference ---\n",
    "    # Difference = Original Accuracy - Accuracy without the feature\n",
    "    diff = original_accuracy - accuracy_subset\n",
    "    accuracy_diffs[feature_to_remove] = diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'industry': 0.0, 'employment_status': -0.0034129692832765013, 'lead_score': 0.0}\n",
      "Smallest difference feature: employment_status\n"
     ]
    }
   ],
   "source": [
    "# Find the feature with the smallest difference (closest to zero or most negative)\n",
    "smallest_diff_feature = min(accuracy_diffs, key=accuracy_diffs.get)\n",
    "\n",
    "print(accuracy_diffs)\n",
    "print(f\"Smallest difference feature: {smallest_diff_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C= 0.01: Accuracy=0.700\n",
      "C=  0.1: Accuracy=0.700\n",
      "C=    1: Accuracy=0.700\n",
      "C=   10: Accuracy=0.700\n",
      "C=  100: Accuracy=0.700\n",
      "\n",
      "Best C for maximum accuracy is: 0.01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "C_values = [0.01, 0.1, 1, 10, 100]\n",
    "best_accuracy = -1\n",
    "best_C = None\n",
    "results_q6 = {}\n",
    "\n",
    "for C in C_values:\n",
    "    # Train the model with the current C\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and calculate accuracy on validation set\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    accuracy_C = accuracy_score(y_val, y_pred_val)\n",
    "    rounded_accuracy = round(accuracy_C, 3)\n",
    "    results_q6[C] = rounded_accuracy\n",
    "    \n",
    "    print(f\"C={C:5}: Accuracy={rounded_accuracy:.3f}\")\n",
    "\n",
    "    # Check for best C (and select smallest C if accuracies are tied)\n",
    "    if accuracy_C > best_accuracy:\n",
    "        best_accuracy = accuracy_C\n",
    "        best_C = C\n",
    "    elif accuracy_C == best_accuracy:\n",
    "        best_C = min(best_C, C)\n",
    "\n",
    "print(f\"\\nBest C for maximum accuracy is: {best_C}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
